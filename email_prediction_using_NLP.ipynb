{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDAbUQ+Xo49QS2HTSDvMCD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunak451/project/blob/main/email_prediction_using_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pr1D0RMTLj9p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import Required Libraries"
      ],
      "metadata": {
        "id": "RA0lI1VlL2NJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Download NLTK stopwords (run once)\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "YjEk7GpHL7Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load and Explore the Dataset"
      ],
      "metadata": {
        "id": "N-vpUDtyMDAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset (replace with your dataset path)\n",
        "# Dataset format should have at least two columns: 'text' and 'label' (0=ham, 1=spam)\n",
        "df = pd.read_csv('spam_emails.csv')  # Example dataset\n",
        "\n",
        "# If using the common spam dataset with 'v1' and 'v2' columns:\n",
        "# df = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "# df = df[['v1', 'v2']]\n",
        "# df.columns = ['label', 'text']\n",
        "\n",
        "print(df.head())\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nLabel Distribution:\")\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "# Visualize the distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='label', data=df)\n",
        "plt.title('Distribution of Spam vs Ham Emails')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t-djrhzoMJ6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Text Preprocessing"
      ],
      "metadata": {
        "id": "XVvNs235MRRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = ''.join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Tokenize\n",
        "    words = text.split()\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply preprocessing\n",
        "df['processed_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Example of preprocessed text\n",
        "print(\"\\nOriginal Text:\")\n",
        "print(df['text'].iloc[0])\n",
        "print(\"\\nProcessed Text:\")\n",
        "print(df['processed_text'].iloc[0])"
      ],
      "metadata": {
        "id": "6mZRxyRLMVRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Feature Extraction (TF-IDF)"
      ],
      "metadata": {
        "id": "T-yto56JMaMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to numerical features using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = tfidf_vectorizer.fit_transform(df['processed_text']).toarray()\n",
        "y = df['label'].values\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
        "print(f\"Testing set shape: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "p092HxK1Mf2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Model Training and Evaluation\n",
        "5.1 Naive Bayes Classifier\n"
      ],
      "metadata": {
        "id": "6zpEtveXMyWN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5q7jOwtsM9HX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "y_pred_nb = nb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nNaive Bayes Classifier:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_nb):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Naive Bayes Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZYKC9cahM6Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2 Support Vector Machine (SVM)"
      ],
      "metadata": {
        "id": "OoFMtI4LNHKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM Classifier\n",
        "svm_classifier = SVC(kernel='linear', probability=True)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "y_pred_svm = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nSVM Classifier:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Greens')\n",
        "plt.title('SVM Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jFPj33z0NLUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.3 Random Forest Classifier"
      ],
      "metadata": {
        "id": "ZRI_yohRNPFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nRandom Forest Classifier:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Oranges')\n",
        "plt.title('Random Forest Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iQDC9wVuNTrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Model Comparison and Selection"
      ],
      "metadata": {
        "id": "X24qwAcSNWgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model accuracies\n",
        "models = ['Naive Bayes', 'SVM', 'Random Forest']\n",
        "accuracies = [accuracy_score(y_test, y_pred_nb),\n",
        "              accuracy_score(y_test, y_pred_svm),\n",
        "              accuracy_score(y_test, y_pred_rf)]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=models, y=accuracies)\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0.8, 1.0)\n",
        "plt.show()\n",
        "\n",
        "# Select the best model (here we'll choose SVM based on accuracy)\n",
        "best_model = svm_classifier"
      ],
      "metadata": {
        "id": "8Zqoa-RrNbcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Save the Model for Future Use"
      ],
      "metadata": {
        "id": "_xLasprQNfFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pickle\n",
        "\n",
        "# Save the model and vectorizer\n",
        "joblib.dump(best_model, 'spam_classifier_model.pkl')\n",
        "pickle.dump(tfidf_vectorizer, open('tfidf_vectorizer.pkl', 'wb'))\n",
        "\n",
        "print(\"Model and vectorizer saved successfully!\")"
      ],
      "metadata": {
        "id": "X5xK9Q8GNjvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Create a Prediction Function"
      ],
      "metadata": {
        "id": "oZFA9dwvNo6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_spam(email_text):\n",
        "    # Load the model and vectorizer\n",
        "    model = joblib.load('spam_classifier_model.pkl')\n",
        "    vectorizer = pickle.load(open('tfidf_vectorizer.pkl', 'rb'))\n",
        "\n",
        "    # Preprocess the text\n",
        "    processed_text = preprocess_text(email_text)\n",
        "\n",
        "    # Vectorize the text\n",
        "    text_vector = vectorizer.transform([processed_text]).toarray()\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(text_vector)\n",
        "    probability = model.predict_proba(text_vector)\n",
        "\n",
        "    # Return result\n",
        "    if prediction[0] == 1:\n",
        "        return f\"SPAM (Confidence: {probability[0][1]*100:.2f}%)\"\n",
        "    else:\n",
        "        return f\"NOT SPAM (Confidence: {probability[0][0]*100:.2f}%)\"\n",
        "\n",
        "# Test the function\n",
        "test_email = \"Congratulations! You've won a $1000 Walmart gift card. Click here to claim your prize now!\"\n",
        "print(\"\\nTest Email Prediction:\")\n",
        "print(predict_spam(test_email))\n",
        "\n",
        "test_email2 = \"Hi John, just checking in about our meeting tomorrow at 2pm. Please let me know if that still works for you.\"\n",
        "print(\"\\nTest Email 2 Prediction:\")\n",
        "print(predict_spam(test_email2))"
      ],
      "metadata": {
        "id": "-QgIUBhVNtN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Optional: Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "TcY7whv3Nw4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Example for SVM tuning\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)\n",
        "\n",
        "# Use the best estimator\n",
        "best_svm = grid_search.best_estimator_\n",
        "y_pred_best = best_svm.predict(X_test)\n",
        "print(\"\\nTuned SVM Accuracy:\", accuracy_score(y_test, y_pred_best))"
      ],
      "metadata": {
        "id": "9em3OEU2N10e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Deployment Considerations\n",
        "For deploying this model, you could:\n",
        "\n",
        "Create a Flask/Django web application\n",
        "\n",
        "Build a Chrome extension for email clients\n",
        "\n",
        "Integrate with email servers directly\n",
        "\n",
        "Create an API endpoint for email services to query"
      ],
      "metadata": {
        "id": "HgnUDV8RN5Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load model and vectorizer at startup\n",
        "model = joblib.load('spam_classifier_model.pkl')\n",
        "vectorizer = pickle.load(open('tfidf_vectorizer.pkl', 'rb'))\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    email_text = data['text']\n",
        "\n",
        "    processed_text = preprocess_text(email_text)\n",
        "    text_vector = vectorizer.transform([processed_text]).toarray()\n",
        "    prediction = model.predict(text_vector)\n",
        "    probability = model.predict_proba(text_vector)\n",
        "\n",
        "    result = {\n",
        "        'prediction': int(prediction[0]),\n",
        "        'confidence': float(probability[0][prediction[0]]),\n",
        "        'is_spam': bool(prediction[0])\n",
        "    }\n",
        "\n",
        "    return jsonify(result)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "McSMubGLOCle"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}