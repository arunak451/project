{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQ0S2IZiJeddcdkTNvdO6a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunak451/project/blob/main/customer_churn_prdiction_using_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdNEwO2fIdQa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import Required Libraries"
      ],
      "metadata": {
        "id": "k3sVZnsZIopO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "eFwESQ70IqXj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load and Explore the Data"
      ],
      "metadata": {
        "id": "H9sfvCXII1ET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "# Display basic info\n",
        "print(data.info())\n",
        "print(data.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Basic statistics\n",
        "print(data.describe())"
      ],
      "metadata": {
        "id": "xP9EIJMVI7K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Data Preprocessing"
      ],
      "metadata": {
        "id": "BmwgkbwLJBhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop customer ID as it's not useful for prediction\n",
        "data.drop('customerID', axis=1, inplace=True)\n",
        "\n",
        "# Convert TotalCharges to numeric (it's loaded as object because of empty strings)\n",
        "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\n",
        "\n",
        "# Fill missing values (only in TotalCharges)\n",
        "data['TotalCharges'].fillna(data['TotalCharges'].median(), inplace=True)\n",
        "\n",
        "# Convert Churn to binary (0/1)\n",
        "data['Churn'] = data['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "# Separate categorical and numerical columns\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns\n",
        "numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns.drop('Churn')\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Check class distribution\n",
        "print(data['Churn'].value_counts(normalize=True))\n",
        "\n",
        "# Visualize class imbalance\n",
        "sns.countplot(x='Churn', data=data)\n",
        "plt.title('Class Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AKEa54XcJF2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Feature Engineering and Splitting Data"
      ],
      "metadata": {
        "id": "rPjd3c-HJOgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = data.drop('Churn', axis=1)\n",
        "y = data['Churn']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "# Handle class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "NFaHFoP6JTiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Model Building and Evaluation"
      ],
      "metadata": {
        "id": "qxQeWkvaJX9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Classification report\n",
        "    cr = classification_report(y_test, y_pred)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Not Churn', 'Churn'],\n",
        "                yticklabels=['Not Churn', 'Churn'])\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.show()\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\", cr)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "kPtsRWZHJb_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "MV4R4E7jJlGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "print(\"Logistic Regression:\")\n",
        "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr = evaluate_model(lr, X_train_smote, y_train_smote, X_test, y_test)"
      ],
      "metadata": {
        "id": "0GR9XrHqJqUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "Bvsi5fm2Jzdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "print(\"\\nRandom Forest:\")\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf = evaluate_model(rf, X_train_smote, y_train_smote, X_test, y_test)\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': rf.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance.head(10))\n",
        "plt.title('Top 10 Important Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S-f5Vw1RJ3ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting"
      ],
      "metadata": {
        "id": "y7nGbNQZJ7w4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosting\n",
        "print(\"\\nGradient Boosting:\")\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb = evaluate_model(gb, X_train_smote, y_train_smote, X_test, y_test)"
      ],
      "metadata": {
        "id": "HS8woGU9KAP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "E50JUQiwKEJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    scoring='roc_auc'\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate best model\n",
        "best_rf = grid_search.best_estimator_\n",
        "print(\"\\nTuned Random Forest:\")\n",
        "best_rf = evaluate_model(best_rf, X_train_smote, y_train_smote, X_test, y_test)"
      ],
      "metadata": {
        "id": "HU_oX46RKIEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Final Model Selection and Deployment"
      ],
      "metadata": {
        "id": "hBNAERmpKNyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final model\n",
        "import joblib\n",
        "\n",
        "# Save model\n",
        "joblib.dump(best_rf, 'churn_prediction_model.pkl')\n",
        "\n",
        "# Save scaler\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "# To load and use the model later:\n",
        "# model = joblib.load('churn_prediction_model.pkl')\n",
        "# scaler = joblib.load('scaler.pkl')"
      ],
      "metadata": {
        "id": "6o6hWoSiKbdQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}